{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navyarawal/Osteosarcoma_Detection/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrniCMQgCWqk",
        "outputId": "b42c60f9-6cea-4ec4-90d0-3f3b97f3c9e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive to access the data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Define the paths to the data in your Google Drive\n",
        "data_dir = '/content/drive/MyDrive/Osteosarcoma'\n",
        "train_dir = os.path.join(data_dir, 'TrainingSet')\n",
        "val_dir = os.path.join(data_dir, 'ValidationSet')\n",
        "test_dir = os.path.join(data_dir, 'TestSet')\n",
        "train_csv = os.path.join(data_dir, 'TrainingSetData.csv')\n",
        "val_csv = os.path.join(data_dir, 'ValidationSetData.csv')\n",
        "test_csv = os.path.join(data_dir, 'TestSetData.csv')\n",
        "\n",
        "# Define label-to-integer mapping\n",
        "label_map = {\n",
        "    'Non-Viable-Tumor': 0,\n",
        "    'Non-Tumor': 1,\n",
        "    'Viable': 2\n",
        "}\n",
        "\n",
        "# Data augmentation and transformation\n",
        "data_gen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True\n",
        ")\n",
        "\n",
        "# Custom dataset class with one-hot encoding for labels\n",
        "class CustomDataset(tf.keras.utils.Sequence):\n",
        "    def __init__(self, csv_file, root_dir, batch_size=16, shuffle=True):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.data) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_data = self.data.iloc[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        images = []\n",
        "        labels = []\n",
        "        for _, row in batch_data.iterrows():\n",
        "            img_name = os.path.join(self.root_dir, row['img_name'])\n",
        "            try:\n",
        "                image = tf.keras.preprocessing.image.load_img(img_name, target_size=(375, 375))\n",
        "                image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "                images.append(image)\n",
        "                label = label_map[row['class']]\n",
        "                labels.append(tf.keras.utils.to_categorical(label, num_classes=3))\n",
        "            except FileNotFoundError:\n",
        "                print()\n",
        "\n",
        "        images = np.array(images)\n",
        "        labels = np.array(labels)\n",
        "        return images, labels\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            self.data = self.data.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Create datasets and dataloaders with the updated column names\n",
        "train_dataset = CustomDataset(train_csv, train_dir, batch_size=32, shuffle=True)  # Reduce batch size for training\n",
        "val_dataset = CustomDataset(val_csv, val_dir, batch_size=16, shuffle=False)\n",
        "test_dataset = CustomDataset(test_csv, test_dir, batch_size=8, shuffle=False)  # Reduce batch size for testing\n",
        "\n",
        "# Create a simpler CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(375, 375, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.7),  # Increase dropout rate\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.7),  # Increase dropout rate\n",
        "    Dense(3, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVj900gjCeDw",
        "outputId": "968f6001-e255-4e57-adf0-b3c450efecf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-trained weights loaded successfully!\n",
            "Epoch 1/1\n",
            "\n",
            "\n",
            " 4/31 [==>...........................] - ETA: 13s - loss: 0.3130 - accuracy: 0.8504\n",
            "\n",
            "18/31 [================>.............] - ETA: 9s - loss: 0.3997 - accuracy: 0.8377 \n",
            "22/31 [====================>.........] - ETA: 6s - loss: 0.3836 - accuracy: 0.8471\n",
            "29/31 [===========================>..] - ETA: 1s - loss: 0.3756 - accuracy: 0.8483\n",
            "31/31 [==============================] - 31s 936ms/step - loss: 0.3779 - accuracy: 0.8489 - val_loss: 0.7969 - val_accuracy: 0.6985 - lr: 1.0000e-05\n",
            "25/25 [==============================] - 5s 187ms/step - loss: 0.5187 - accuracy: 0.8090\n",
            "Test Loss: 0.5187 | Test Accuracy: 80.90%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "pretrained_weights_path = '/content/drive/MyDrive/Osteosarcoma/model_weights_simpler_cnn(8090).h5'\n",
        "if os.path.exists(pretrained_weights_path):\n",
        "    model.load_weights(pretrained_weights_path)\n",
        "    print(\"Pre-trained weights loaded successfully!\")\n",
        "else:\n",
        "    print(\"Pre-trained weights not found. Starting training from scratch.\")\n",
        "\n",
        "# Compile the model with categorical cross-entropy loss and a smaller learning rate\n",
        "optimizer = Adam(learning_rate=0.00001)  # Reduce the learning rate\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define EarlyStopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Define Redu1eLROnPlateau callback\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1, min_lr=0.0001)\n",
        "\n",
        "# Training the model with EarlyStopping and ReduceLROnPlateau callbacks\n",
        "num_epochs = 1  # Change this to the desired number of epochs\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "    model.fit(train_dataset, validation_data=val_dataset, epochs=1, callbacks=[early_stopping, reduce_lr])\n",
        "#model.fit(train_dataset, validation_data=val_dataset, epochs=1, callbacks=[early_stopping, reduce_lr])\n",
        "\n",
        "# Save model weights\n",
        "model.save_weights('/content/drive/MyDrive/Osteosarcoma/model_weights_simpler_cnn.h5')\n",
        "\n",
        "\n",
        "\n",
        "# Evaluate on test set\n",
        "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
        "test_accuracy_percentage = test_accuracy * 100\n",
        "print(f'Test Loss: {test_loss:.4f} | Test Accuracy: {test_accuracy_percentage:.2f}%')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "!pip install scikit-learn\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for batch in test_dataset:\n",
        "    images, labels = batch\n",
        "    y_true.extend(np.argmax(labels, axis=1))  # Convert one-hot encoded labels back to integer labels\n",
        "    predictions = model.predict(images)\n",
        "    y_pred.extend(np.argmax(predictions, axis=1))\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Calculate the recall, precision, and F1 score\n",
        "report = classification_report(y_true, y_pred, target_names=label_map.keys())\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t59FaHbSD5sg",
        "outputId": "b9506960-d111-41e5-d14c-dbd26c070e2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Confusion Matrix:\n",
            "[[64  9  4]\n",
            " [16 78  2]\n",
            " [ 4  3 19]]\n",
            "Classification Report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "Non-Viable-Tumor       0.76      0.83      0.80        77\n",
            "       Non-Tumor       0.87      0.81      0.84        96\n",
            "          Viable       0.76      0.73      0.75        26\n",
            "\n",
            "        accuracy                           0.81       199\n",
            "       macro avg       0.80      0.79      0.79       199\n",
            "    weighted avg       0.81      0.81      0.81       199\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNivs/aDE26xAsbe6OvO2iC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}